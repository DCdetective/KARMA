nohup: ignoring input
Args in experiment:
Namespace(random_seed=2024, task_name='long_term_forecast', is_training=1, model_id='traffic_96_96', model='Mamba', data='custom', root_path='./dataset/traffic/', data_path='traffic.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=862, dec_in=7, c_out=862, dropout=0.1, embed='timeF', activation='gelu', d_model=128, expand=2, d_state=16, d_conv=4, top_k=5, num_kernels=6, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, channel_independence=1, decomp_method='moving_avg', seg_len=48, use_norm=1, down_sampling_layers=0, down_sampling_window=1, down_sampling_method=None, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='mambaTest', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2)
Use GPU: cuda:0
>>>>>>>start training : long_term_forecast_traffic_96_96_Mamba_custom_ftM_sl96_ll48_pl96_dm128_nh8_el2_dl1_df2048_expand2_dc4_fc1_ebtimeF_dtTrue_mambaTest_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 12089
val 1661
test 3413
	iters: 100, epoch: 1 | loss: 0.5232263
	speed: 0.1458s/iter; left time: 536.8505s
